{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813f67e377320599",
   "metadata": {},
   "source": [
    "### Importing initial modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c1cf7d26a14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932226e998e0486",
   "metadata": {},
   "source": [
    "### Changing to the correct directory if not already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46214bc5099021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/baari/Desktop/hard-drive-predictive-maintenance'\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9d3946a3811f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Q1_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9fb9a0dda7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0498dd054500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe0285c6bb9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa4660f7d3c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba589ddef52b7a7",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355a65a604298c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = np.prod(df.shape)\n",
    "total_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92eecac9a1c7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424b805a16b7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_missing = missing_values_count.sum()\n",
    "total_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540237e25b97b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = total_missing / total_cells * 100\n",
    "print(f'{percent_missing}% of the data is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f92ee2fd4fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_before = df.columns\n",
    "\n",
    "# Remove columns that have all null values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "columns_after = df.columns\n",
    "\n",
    "removed_columns = set(columns_before) - set(columns_after)\n",
    "print(f'Columns removed: {removed_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6ad5c6c1e6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = np.prod(df.shape)\n",
    "total_missing = df.isnull().sum().sum()\n",
    "percent_missing = total_missing / total_cells * 100\n",
    "print(f'{percent_missing}% of the data is missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4b5047d0f44e9",
   "metadata": {},
   "source": [
    "# Computing failure rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36461d685b55f5e",
   "metadata": {},
   "source": [
    "### Creating a dataframe that has the number of drive days for each model. Drive days refers to the number of days a hard drive has been running (the number of rows in the main dataframe for that model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c339f61e8ea42",
   "metadata": {},
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE drive_days AS \n",
    "    SELECT model, count(*) AS drive_days \n",
    "    FROM drive_stats \n",
    "    GROUP BY model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93275ad87496f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups the dataframe by the 'model' column and calculates the size (number of rows) for each group\n",
    "# The .size() gets the count of occurrences for each model\n",
    "drive_days = df.groupby('model').size().reset_index(name='drive_days')\n",
    "\n",
    "# Sort the dataframe by 'drive_days' in descending order\n",
    "drive_days = drive_days.sort_values(by='drive_days', ascending=False).reset_index(drop=True)\n",
    "\n",
    "drive_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df54ff7d2fbe126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total drive days across all models (which is also the total rows)\n",
    "total_drive_days = len(df)\n",
    "total_drive_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d92d96f89d9fed",
   "metadata": {},
   "source": [
    "### Creating a table that has the number of failures for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e72d03ce2217dd",
   "metadata": {},
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE failures AS\n",
    "    SELECT model, count(*) AS failures\n",
    "    FROM drive_stats\n",
    "    WHERE failure = 1\n",
    "    GROUP BY model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8642a2dc2dc6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = df[df['failure'] == 1].groupby('model').size().reset_index(name='failures')\n",
    "failures = failures.sort_values(by='failures', ascending=False).reset_index(drop=True)\n",
    "failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a852fd939e3a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total failures\n",
    "total_failures = (df['failure'] == 1).sum()\n",
    "print(f'Total failures: {total_failures}')\n",
    "\n",
    "# Calculating the total unique days\n",
    "total_unique_days = df['date'].nunique()\n",
    "print(f'Total unique days: {total_unique_days}')\n",
    "\n",
    "print(f'Total drive days: {total_drive_days}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d2c0f96945e09",
   "metadata": {},
   "source": [
    "### So we have 428 drive failures in 9,577,046 drive days of operation.\n",
    "### The daily failure rate is the drive failures / drive days.\n",
    "### The annual failure rate would be the daily failure rate * 365 (assuming the rest of the year would have similar results to the first 3 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413230786f83b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_failure_rate = (total_failures / total_drive_days) * 100\n",
    "annual_failure_rate = daily_failure_rate * 365\n",
    "print(f'Daily failure rate is {daily_failure_rate}%')\n",
    "print(f'Annual failure rate is {annual_failure_rate}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7f2841ddd733b",
   "metadata": {},
   "source": [
    "### Creating a table that has the number of drives for each model as of January 31st 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe8a272ed8c922",
   "metadata": {},
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE model_count AS\n",
    "    SELECT model, count(*) AS count\n",
    "    FROM drive_stats\n",
    "    WHERE date = '2019-01-31'\n",
    "    GROUP BY model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037fa1190da248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime type (if not already)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter rows for specific date and calculate the number of drives for each model\n",
    "model_count = df[df['date'] == '2019-01-31'].groupby('model').size().reset_index(name='count')\n",
    "\n",
    "# Sort the dataframe by 'count' in descending order\n",
    "model_count = model_count.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "model_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b98f147c45f5ba",
   "metadata": {},
   "source": [
    "### On a specific day, (e.g. 1st Jan, feb, mar) how many hard drives are there for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73877d4ef3fb998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_count_jan = df[df['date'] == '2019-01-01'].groupby('model').size().reset_index(name='1st Jan')\n",
    "# model_count_feb = df[df['date'] == '2019-02-01'].groupby('model').size().reset_index(name='1st Feb')\n",
    "# model_count_mar = df[df['date'] == '2019-03-01'].groupby('model').size().reset_index(name='1st Mar')\n",
    "# \n",
    "# # Merge the DataFrames on the 'model' column\n",
    "# model_count = pd.merge(model_count_jan, model_count_feb, on='model', how='outer')\n",
    "# model_count = pd.merge(model_count, model_count_mar, on='model', how='outer')\n",
    "# \n",
    "# # Fill NaN values with 0 (models that didn't have data for a specific month)\n",
    "# model_count = model_count.fillna(0)\n",
    "# \n",
    "# # Sort the dataframe by '1st Jan' in descending order\n",
    "# model_count = model_count.sort_values(by='1st Jan', ascending=False).reset_index(drop=True)\n",
    "# \n",
    "# model_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aba4454f4448f",
   "metadata": {},
   "source": [
    "### Join the tables together and compute the annual failure rate\n",
    "### drive_years = drive_days / 365\n",
    "### Annual failure rate = (number of failures / number of drive years) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8123ad9a784d5",
   "metadata": {},
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE failure_rates AS\n",
    "    SELECT drive_days.model AS model,\n",
    "           drive_days.drive_days AS drive_days,\n",
    "           failures.failures AS failures, \n",
    "           100.0 * (1.0 * failures) / (drive_days / 365.0) AS annual_failure_rate\n",
    "    FROM drive_days, failures, model_count\n",
    "    WHERE drive_days.model = failures.model\n",
    "      AND model_count.model = failures.model\n",
    "    ORDER BY model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a02924dcaa5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976657c71e580de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443737f23d2b45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65901a04135c5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "# The on='model' argument in the pd.merge function indicates that the merge should be performed \n",
    "# based on the model column, and only rows with matching model values in both DataFrames will \n",
    "# be included in the result.\n",
    "merged_df = pd.merge(drive_days, failures, on='model')\n",
    "merged_df = pd.merge(merged_df, model_count, on='model')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883658ec281cdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annual failure rate\n",
    "failure_rates = merged_df.copy()\n",
    "failure_rates['drive_years'] = failure_rates['drive_days'] / 365\n",
    "failure_rates['annual_failure_rate (%)'] = (failure_rates['failures'] / failure_rates['drive_years']) * 100\n",
    "failure_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fa828889e8b03",
   "metadata": {},
   "source": [
    "### Testing out rule 2 on table 6 from https://www.kdd.org/kdd2016/papers/files/adf0849-botezatuA.pdf\n",
    "### Seems like the information is not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f4f07bebc195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['smart_197_raw'] >= 2]\n",
    "filtered_df[['model', 'failure', 'smart_197_raw']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
