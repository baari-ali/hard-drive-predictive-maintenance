{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Importing initial modules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687b31552889d0ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T21:01:45.913252100Z",
     "start_time": "2024-02-01T21:01:45.476456500Z"
    }
   },
   "id": "905ea8dc2f99c4e4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\baari\\\\Documents\\\\uni\\\\y3\\\\project\\\\final_project\\\\hard-drive-predictive-maintenance'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T21:02:32.550604100Z",
     "start_time": "2024-02-01T21:02:32.501239900Z"
    }
   },
   "id": "76c32991d76e74b5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('Q1_2019.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faa43e5012a59039"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbbd737762f04533"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c757e88f2df4d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5592ea1dd999175"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['failure'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf15b7128307d584"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0468d9ab05104"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_cells = np.prod(df.shape)\n",
    "total_cells"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d34c5b94a0fb02f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count[0:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4c80076d8c1d310"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_missing = missing_values_count.sum()\n",
    "total_missing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78dbe483084928c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "percent_missing = total_missing / total_cells * 100\n",
    "print(f'{percent_missing}% of the data is missing')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32358f22cd1ad239"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "columns_before = df.columns\n",
    "\n",
    "# Remove columns that have all null values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "columns_after = df.columns\n",
    "\n",
    "removed_columns = set(columns_before) - set(columns_after)\n",
    "print(f'Columns removed: {removed_columns}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a8c5c103dccb260"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_cells = np.prod(df.shape)\n",
    "total_missing = df.isnull().sum().sum()\n",
    "percent_missing = total_missing / total_cells * 100\n",
    "print(f'{percent_missing}% of the data is missing')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ee72ebd4ca4779f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Computing failure rates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bee5aa9dd42dd385"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a dataframe that has the number of drive days for each model. Drive days refers to the number of days a hard drive has been running (the number of rows in the main dataframe for that model)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf7f15b4037e976"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE drive_days AS \n",
    "    SELECT model, count(*) AS drive_days \n",
    "    FROM drive_stats \n",
    "    GROUP BY model;"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b11b88ac63d1ac72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Groups the dataframe by the 'model' column and calculates the size (number of rows) for each group\n",
    "# The .size() gets the count of occurrences for each model\n",
    "drive_days = df.groupby('model').size().reset_index(name='drive_days')\n",
    "\n",
    "# Sort the dataframe by 'drive_days' in descending order\n",
    "drive_days = drive_days.sort_values(by='drive_days', ascending=False).reset_index(drop=True)\n",
    "\n",
    "drive_days"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b26fbe18b64f71e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Total drive days across all models (which is also the total rows)\n",
    "total_drive_days = len(df)\n",
    "total_drive_days"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6745df993bb54af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a table that has the number of failures for each model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64c6c5fd9011c77d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE failures AS\n",
    "    SELECT model, count(*) AS failures\n",
    "    FROM drive_stats\n",
    "    WHERE failure = 1\n",
    "    GROUP BY model;"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "778fe30cbffc0b5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "failures = df[df['failure'] == 1].groupby('model').size().reset_index(name='failures')\n",
    "failures = failures.sort_values(by='failures', ascending=False).reset_index(drop=True)\n",
    "failures"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c1d0301701fe93d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculating the total failures\n",
    "total_failures = (df['failure'] == 1).sum()\n",
    "print(f'Total failures: {total_failures}')\n",
    "\n",
    "# Calculating the total unique days\n",
    "total_unique_days = df['date'].nunique()\n",
    "print(f'Total unique days: {total_unique_days}')\n",
    "\n",
    "print(f'Total drive days: {total_drive_days}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92257ff455e547c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### So we have 428 drive failures in 9,577,046 drive days of operation.\n",
    "### The daily failure rate is the drive failures / drive days.\n",
    "### The annual failure rate would be the daily failure rate * 365 (assuming the rest of the year would have similar results to the first 3 months)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9b7111506109aee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "daily_failure_rate = (total_failures / total_drive_days) * 100\n",
    "annual_failure_rate = daily_failure_rate * 365\n",
    "print(f'Daily failure rate is {daily_failure_rate}%')\n",
    "print(f'Annual failure rate is {annual_failure_rate}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76287739de88f0b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a table that has the number of drives for each model as of January 31st 2019"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff153f423af77eb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE model_count AS\n",
    "    SELECT model, count(*) AS count\n",
    "    FROM drive_stats\n",
    "    WHERE date = '2019-01-31'\n",
    "    GROUP BY model;"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de035867e7573502"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime type (if not already)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter rows for specific date and calculate the number of drives for each model\n",
    "model_count = df[df['date'] == '2019-01-31'].groupby('model').size().reset_index(name='count')\n",
    "\n",
    "# Sort the dataframe by 'count' in descending order\n",
    "model_count = model_count.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "model_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b53f18b947e6695"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On a specific day, (e.g. 1st Jan, feb, mar) how many hard drives are there for each model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5bcdf461f4153ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model_count_jan = df[df['date'] == '2019-01-01'].groupby('model').size().reset_index(name='1st Jan')\n",
    "# model_count_feb = df[df['date'] == '2019-02-01'].groupby('model').size().reset_index(name='1st Feb')\n",
    "# model_count_mar = df[df['date'] == '2019-03-01'].groupby('model').size().reset_index(name='1st Mar')\n",
    "# \n",
    "# # Merge the DataFrames on the 'model' column\n",
    "# model_count = pd.merge(model_count_jan, model_count_feb, on='model', how='outer')\n",
    "# model_count = pd.merge(model_count, model_count_mar, on='model', how='outer')\n",
    "# \n",
    "# # Fill NaN values with 0 (models that didn't have data for a specific month)\n",
    "# model_count = model_count.fillna(0)\n",
    "# \n",
    "# # Sort the dataframe by '1st Jan' in descending order\n",
    "# model_count = model_count.sort_values(by='1st Jan', ascending=False).reset_index(drop=True)\n",
    "# \n",
    "# model_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4409988c70a69eb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Join the tables together and compute the annual failure rate\n",
    "### drive_years = drive_days / 365\n",
    "### Annual failure rate = (number of failures / number of drive years) * 100"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "810b8e76aaff0603"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Written in SQL like this:\n",
    "\n",
    "CREATE TABLE failure_rates AS\n",
    "    SELECT drive_days.model AS model,\n",
    "           drive_days.drive_days AS drive_days,\n",
    "           failures.failures AS failures, \n",
    "           100.0 * (1.0 * failures) / (drive_days / 365.0) AS annual_failure_rate\n",
    "    FROM drive_days, failures, model_count\n",
    "    WHERE drive_days.model = failures.model\n",
    "      AND model_count.model = failures.model\n",
    "    ORDER BY model;"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c0e5f6c37203b25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "drive_days"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43eb64ce7b1eb63a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "failures"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b34dd8c312788d2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a66c303d88030fd2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "# The on='model' argument in the pd.merge function indicates that the merge should be performed \n",
    "# based on the model column, and only rows with matching model values in both DataFrames will \n",
    "# be included in the result.\n",
    "merged_df = pd.merge(drive_days, failures, on='model')\n",
    "merged_df = pd.merge(merged_df, model_count, on='model')\n",
    "merged_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b13fa98c144e9ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate annual failure rate\n",
    "failure_rates = merged_df.copy()\n",
    "failure_rates['drive_years'] = failure_rates['drive_days'] / 365\n",
    "failure_rates['annual_failure_rate (%)'] = (failure_rates['failures'] / failure_rates['drive_years']) * 100\n",
    "failure_rates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b59b9155efcd908"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing out rule 2 on table 6 from https://www.kdd.org/kdd2016/papers/files/adf0849-botezatuA.pdf\n",
    "### Seems like the information is not true"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec131425ff6ed5dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_df = df[df['smart_197_raw'] >= 2]\n",
    "filtered_df[['model', 'failure', 'smart_197_raw']].head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3061cbd1499a990e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
